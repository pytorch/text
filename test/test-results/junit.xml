<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="4" skipped="0" tests="4" time="7.872" timestamp="2022-10-05T18:52:49.766322" hostname="vitaly-desktop"><testcase classname="test.torchtext_unittest.test_build.TestDataUtils" name="test_get_tokenizer_moses" time="0.001"><failure message="ModuleNotFoundError: No module named 'sacremoses'">self = &lt;torchtext_unittest.test_build.TestDataUtils testMethod=test_get_tokenizer_moses&gt;

    def test_get_tokenizer_moses(self) -&gt; None:
        # Test Moses option.
        # Note that internally, MosesTokenizer converts to unicode if applicable
&gt;       moses_tokenizer = torchtext.data.get_tokenizer("moses")

torchtext_unittest/test_build.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

tokenizer = 'moses', language = 'en'

    def get_tokenizer(tokenizer, language="en"):
        r"""
        Generate tokenizer function for a string sentence.
    
        Args:
            tokenizer: the name of tokenizer function. If None, it returns split()
                function, which splits the string sentence by space.
                If basic_english, it returns _basic_english_normalize() function,
                which normalize the string first and split by space. If a callable
                function, it will return the function. If a tokenizer library
                (e.g. spacy, moses, toktok, revtok, subword), it returns the
                corresponding library.
            language: Default en
    
        Examples:
            &gt;&gt;&gt; import torchtext
            &gt;&gt;&gt; from torchtext.data import get_tokenizer
            &gt;&gt;&gt; tokenizer = get_tokenizer("basic_english")
            &gt;&gt;&gt; tokens = tokenizer("You can now install TorchText using pip!")
            &gt;&gt;&gt; tokens
            &gt;&gt;&gt; ['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']
    
        """
    
        # default tokenizer is string.split(), added as a module function for serialization
        if tokenizer is None:
            return _split_tokenizer
    
        if tokenizer == "basic_english":
            if language != "en":
                raise ValueError("Basic normalization is only available for Enlish(en)")
            return _basic_english_normalize
    
        # simply return if a function is passed
        if callable(tokenizer):
            return tokenizer
    
        if tokenizer == "spacy":
            try:
                import spacy
    
                try:
                    spacy = spacy.load(language)
                except IOError:
                    # Model shortcuts no longer work in spaCy 3.0+, try using fullnames
                    # List is from https://github.com/explosion/spaCy/blob/b903de3fcb56df2f7247e5b6cfa6b66f4ff02b62/spacy/errors.py#L789
                    OLD_MODEL_SHORTCUTS = (
                        spacy.errors.OLD_MODEL_SHORTCUTS if hasattr(spacy.errors, "OLD_MODEL_SHORTCUTS") else {}
                    )
                    if language not in OLD_MODEL_SHORTCUTS:
                        raise
                    import warnings
    
                    warnings.warn(
                        f'Spacy model "{language}" could not be loaded, trying "{OLD_MODEL_SHORTCUTS[language]}" instead'
                    )
                    spacy = spacy.load(OLD_MODEL_SHORTCUTS[language])
                return partial(_spacy_tokenize, spacy=spacy)
            except ImportError:
                print("Please install SpaCy. " "See the docs at https://spacy.io for more information.")
                raise
            except AttributeError:
                print(
                    "Please install SpaCy and the SpaCy {} tokenizer. "
                    "See the docs at https://spacy.io for more "
                    "information.".format(language)
                )
                raise
        elif tokenizer == "moses":
            try:
&gt;               from sacremoses import MosesTokenizer
E               ModuleNotFoundError: No module named 'sacremoses'

../torchtext/data/utils.py:122: ModuleNotFoundError</failure></testcase><testcase classname="test.torchtext_unittest.test_build.TestDataUtils" name="test_get_tokenizer_spacy" time="0.001"><failure message="ModuleNotFoundError: No module named 'spacy'">self = &lt;torchtext_unittest.test_build.TestDataUtils testMethod=test_get_tokenizer_spacy&gt;

    def test_get_tokenizer_spacy(self) -&gt; None:
        # Test SpaCy option, and verify it properly handles punctuation.
&gt;       assert torchtext.data.get_tokenizer("spacy", language="en_core_web_sm")(str(self.TEST_STR)) == [
            "A",
            "string",
            ",",
            "particularly",
            "one",
            "with",
            "slightly",
            "complex",
            "punctuation",
            ".",
        ]

torchtext_unittest/test_build.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

tokenizer = 'spacy', language = 'en_core_web_sm'

    def get_tokenizer(tokenizer, language="en"):
        r"""
        Generate tokenizer function for a string sentence.
    
        Args:
            tokenizer: the name of tokenizer function. If None, it returns split()
                function, which splits the string sentence by space.
                If basic_english, it returns _basic_english_normalize() function,
                which normalize the string first and split by space. If a callable
                function, it will return the function. If a tokenizer library
                (e.g. spacy, moses, toktok, revtok, subword), it returns the
                corresponding library.
            language: Default en
    
        Examples:
            &gt;&gt;&gt; import torchtext
            &gt;&gt;&gt; from torchtext.data import get_tokenizer
            &gt;&gt;&gt; tokenizer = get_tokenizer("basic_english")
            &gt;&gt;&gt; tokens = tokenizer("You can now install TorchText using pip!")
            &gt;&gt;&gt; tokens
            &gt;&gt;&gt; ['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']
    
        """
    
        # default tokenizer is string.split(), added as a module function for serialization
        if tokenizer is None:
            return _split_tokenizer
    
        if tokenizer == "basic_english":
            if language != "en":
                raise ValueError("Basic normalization is only available for Enlish(en)")
            return _basic_english_normalize
    
        # simply return if a function is passed
        if callable(tokenizer):
            return tokenizer
    
        if tokenizer == "spacy":
            try:
&gt;               import spacy
E               ModuleNotFoundError: No module named 'spacy'

../torchtext/data/utils.py:91: ModuleNotFoundError</failure></testcase><testcase classname="test.torchtext_unittest.test_build.TestVocab" name="test_download_charngram_vectors" time="3.918"><failure message="FileNotFoundError: [Errno 2] No such file or directory: '.vector_cache/jmt_pre-trained_embeddings.tar.gz'">self = &lt;torchtext.vocab.vectors.CharNGram object at 0x7f94cece7580&gt;, name = 'charNgram.txt', cache = '.vector_cache'
url = 'http://www.logos.t.u-tokyo.ac.jp/~hassy/publications/arxiv2016jmt/jmt_pre-trained_embeddings.tar.gz', max_vectors = None

    def cache(self, name, cache, url=None, max_vectors=None):
        import ssl
    
        ssl._create_default_https_context = ssl._create_unverified_context
        if os.path.isfile(name):
            path = name
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = os.path.join(cache, os.path.basename(name)) + file_suffix
        else:
            path = os.path.join(cache, name)
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = path + file_suffix
    
        if not os.path.isfile(path_pt):
            if not os.path.isfile(path) and url:
                logger.info("Downloading vectors from {}".format(url))
                if not os.path.exists(cache):
                    os.makedirs(cache)
                dest = os.path.join(cache, os.path.basename(url))
                if not os.path.isfile(dest):
                    with tqdm(unit="B", unit_scale=True, miniters=1, desc=dest) as t:
                        try:
&gt;                           urlretrieve(url, dest, reporthook=reporthook(t))

../torchtext/vocab/vectors.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

url = 'http://www.logos.t.u-tokyo.ac.jp/~hassy/publications/arxiv2016jmt/jmt_pre-trained_embeddings.tar.gz'
filename = '.vector_cache/jmt_pre-trained_embeddings.tar.gz', reporthook = &lt;function reporthook.&lt;locals&gt;.inner at 0x7f94ce8d5160&gt;, data = None

    def urlretrieve(url, filename=None, reporthook=None, data=None):
        """
        Retrieve a URL into a temporary location on disk.
    
        Requires a URL argument. If a filename is passed, it is used as
        the temporary file location. The reporthook argument should be
        a callable that accepts a block number, a read size, and the
        total file size of the URL target. The data argument should be
        valid URL encoded data.
    
        If a filename is passed and the URL points to a local resource,
        the result is a copy from local file to new file.
    
        Returns a tuple containing the path to the newly created
        data file as well as the resulting HTTPMessage object.
        """
        url_type, path = _splittype(url)
    
&gt;       with contextlib.closing(urlopen(url, data)) as fp:

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

url = 'http://www.logos.t.u-tokyo.ac.jp/~hassy/publications/arxiv2016jmt/jmt_pre-trained_embeddings.tar.gz', data = None
timeout = &lt;object object at 0x7f9519ac1ab0&gt;

    def urlopen(url, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
                *, cafile=None, capath=None, cadefault=False, context=None):
        '''Open the URL url, which can be either a string or a Request object.
    
        *data* must be an object specifying additional data to be sent to
        the server, or None if no such data is needed.  See Request for
        details.
    
        urllib.request module uses HTTP/1.1 and includes a "Connection:close"
        header in its HTTP requests.
    
        The optional *timeout* parameter specifies a timeout in seconds for
        blocking operations like the connection attempt (if not specified, the
        global default timeout setting will be used). This only works for HTTP,
        HTTPS and FTP connections.
    
        If *context* is specified, it must be a ssl.SSLContext instance describing
        the various SSL options. See HTTPSConnection for more details.
    
        The optional *cafile* and *capath* parameters specify a set of trusted CA
        certificates for HTTPS requests. cafile should point to a single file
        containing a bundle of CA certificates, whereas capath should point to a
        directory of hashed certificate files. More information can be found in
        ssl.SSLContext.load_verify_locations().
    
        The *cadefault* parameter is ignored.
    
        This function always returns an object which can work as a context
        manager and has methods such as
    
        * geturl() - return the URL of the resource retrieved, commonly used to
          determine if a redirect was followed
    
        * info() - return the meta-information of the page, such as headers, in the
          form of an email.message_from_string() instance (see Quick Reference to
          HTTP Headers)
    
        * getcode() - return the HTTP status code of the response.  Raises URLError
          on errors.
    
        For HTTP and HTTPS URLs, this function returns a http.client.HTTPResponse
        object slightly modified. In addition to the three new methods above, the
        msg attribute contains the same information as the reason attribute ---
        the reason phrase returned by the server --- instead of the response
        headers as it is specified in the documentation for HTTPResponse.
    
        For FTP, file, and data URLs and requests explicitly handled by legacy
        URLopener and FancyURLopener classes, this function returns a
        urllib.response.addinfourl object.
    
        Note that None may be returned if no handler handles the request (though
        the default installed global OpenerDirector uses UnknownHandler to ensure
        this never happens).
    
        In addition, if proxy settings are detected (for example, when a *_proxy
        environment variable like http_proxy is set), ProxyHandler is default
        installed and makes sure the requests are handled through the proxy.
    
        '''
        global _opener
        if cafile or capath or cadefault:
            import warnings
            warnings.warn("cafile, capath and cadefault are deprecated, use a "
                          "custom context instead.", DeprecationWarning, 2)
            if context is not None:
                raise ValueError(
                    "You can't pass both context and any of cafile, capath, and "
                    "cadefault"
                )
            if not _have_ssl:
                raise ValueError('SSL support not available')
            context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH,
                                                 cafile=cafile,
                                                 capath=capath)
            https_handler = HTTPSHandler(context=context)
            opener = build_opener(https_handler)
        elif context:
            https_handler = HTTPSHandler(context=context)
            opener = build_opener(https_handler)
        elif _opener is None:
            _opener = opener = build_opener()
        else:
            opener = _opener
&gt;       return opener.open(url, data, timeout)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;
fullurl = 'http://www.logos.t.u-tokyo.ac.jp/~hassy/publications/arxiv2016jmt/jmt_pre-trained_embeddings.tar.gz', data = None
timeout = &lt;object object at 0x7f9519ac1ab0&gt;

    def open(self, fullurl, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT):
        # accept a URL or a Request object
        if isinstance(fullurl, str):
            req = Request(fullurl, data)
        else:
            req = fullurl
            if data is not None:
                req.data = data
    
        req.timeout = timeout
        protocol = req.type
    
        # pre-process request
        meth_name = protocol+"_request"
        for processor in self.process_request.get(protocol, []):
            meth = getattr(processor, meth_name)
            req = meth(req)
    
        sys.audit('urllib.Request', req.full_url, req.data, req.headers, req.get_method())
        response = self._open(req, data)
    
        # post-process response
        meth_name = protocol+"_response"
        for processor in self.process_response.get(protocol, []):
            meth = getattr(processor, meth_name)
&gt;           response = meth(req, response)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:531: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.HTTPErrorProcessor object at 0x7f94ce8ee0d0&gt;, request = &lt;urllib.request.Request object at 0x7f94ce8e08e0&gt;
response = &lt;http.client.HTTPResponse object at 0x7f94ce8ee070&gt;

    def http_response(self, request, response):
        code, msg, hdrs = response.code, response.msg, response.info()
    
        # According to RFC 2616, "2xx" code indicates that the client's
        # request was successfully received, understood, and accepted.
        if not (200 &lt;= code &lt; 300):
&gt;           response = self.parent.error(
                'http', request, response, code, msg, hdrs)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:640: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;, proto = 301
args = ({'default': [&lt;urllib.request.HTTPDefaultErrorHandler object at 0x7f94ce8e0490&gt;], 301: [&lt;urllib.request.HTTPRedirectHa...301', &lt;urllib.request.Request object at 0x7f94ce8e08e0&gt;, &lt;http.client.HTTPResponse object at 0x7f94ce8ee070&gt;, 301, ...)
dict = {'default': [&lt;urllib.request.HTTPDefaultErrorHandler object at 0x7f94ce8e0490&gt;], 301: [&lt;urllib.request.HTTPRedirectHan...PRedirectHandler object at 0x7f94ce8eec10&gt;], 303: [&lt;urllib.request.HTTPRedirectHandler object at 0x7f94ce8eec10&gt;], ...}
meth_name = 'http_error_301', http_err = 1

    def error(self, proto, *args):
        if proto in ('http', 'https'):
            # XXX http[s] protocols are special-cased
            dict = self.handle_error['http'] # https is not different than http
            proto = args[2]  # YUCK!
            meth_name = 'http_error_%s' % proto
            http_err = 1
            orig_args = args
        else:
            dict = self.handle_error
            meth_name = proto + '_error'
            http_err = 0
        args = (dict, proto, meth_name) + args
&gt;       result = self._call_chain(*args)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;
chain = {'default': [&lt;urllib.request.HTTPDefaultErrorHandler object at 0x7f94ce8e0490&gt;], 301: [&lt;urllib.request.HTTPRedirectHan...PRedirectHandler object at 0x7f94ce8eec10&gt;], 303: [&lt;urllib.request.HTTPRedirectHandler object at 0x7f94ce8eec10&gt;], ...}
kind = 301, meth_name = 'http_error_301'
args = (&lt;urllib.request.Request object at 0x7f94ce8e08e0&gt;, &lt;http.client.HTTPResponse object at 0x7f94ce8ee070&gt;, 301, 'Moved Permanently', &lt;http.client.HTTPMessage object at 0x7f94ce8ee5b0&gt;)
handlers = [&lt;urllib.request.HTTPRedirectHandler object at 0x7f94ce8eec10&gt;], handler = &lt;urllib.request.HTTPRedirectHandler object at 0x7f94ce8eec10&gt;
func = &lt;bound method HTTPRedirectHandler.http_error_302 of &lt;urllib.request.HTTPRedirectHandler object at 0x7f94ce8eec10&gt;&gt;

    def _call_chain(self, chain, kind, meth_name, *args):
        # Handlers raise an exception if no one else should try to handle
        # the request, or return None if they can't but another handler
        # could.  Otherwise, they return the response.
        handlers = chain.get(kind, ())
        for handler in handlers:
            func = getattr(handler, meth_name)
&gt;           result = func(*args)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:502: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.HTTPRedirectHandler object at 0x7f94ce8eec10&gt;, req = &lt;urllib.request.Request object at 0x7f94ce8e08e0&gt;
fp = &lt;http.client.HTTPResponse object at 0x7f94ce8ee070&gt;, code = 301, msg = 'Moved Permanently', headers = &lt;http.client.HTTPMessage object at 0x7f94ce8ee5b0&gt;

    def http_error_302(self, req, fp, code, msg, headers):
        # Some servers (incorrectly) return multiple Location headers
        # (so probably same goes for URI).  Use first header.
        if "location" in headers:
            newurl = headers["location"]
        elif "uri" in headers:
            newurl = headers["uri"]
        else:
            return
    
        # fix a possible malformed URL
        urlparts = urlparse(newurl)
    
        # For security reasons we don't allow redirection to anything other
        # than http, https or ftp.
    
        if urlparts.scheme not in ('http', 'https', 'ftp', ''):
            raise HTTPError(
                newurl, code,
                "%s - Redirection to url '%s' is not allowed" % (msg, newurl),
                headers, fp)
    
        if not urlparts.path and urlparts.netloc:
            urlparts = list(urlparts)
            urlparts[2] = "/"
        newurl = urlunparse(urlparts)
    
        # http.client.parse_headers() decodes as ISO-8859-1.  Recover the
        # original bytes and percent-encode non-ASCII bytes, and any special
        # characters such as the space.
        newurl = quote(
            newurl, encoding="iso-8859-1", safe=string.punctuation)
        newurl = urljoin(req.full_url, newurl)
    
        # XXX Probably want to forget about the state of the current
        # request, although that might interact poorly with other
        # handlers that also use handler-specific request attributes
        new = self.redirect_request(req, fp, code, msg, headers, newurl)
        if new is None:
            return
    
        # loop detection
        # .redirect_dict has a key url if url was previously visited.
        if hasattr(req, 'redirect_dict'):
            visited = new.redirect_dict = req.redirect_dict
            if (visited.get(newurl, 0) &gt;= self.max_repeats or
                len(visited) &gt;= self.max_redirections):
                raise HTTPError(req.full_url, code,
                                self.inf_msg + msg, headers, fp)
        else:
            visited = new.redirect_dict = req.redirect_dict = {}
        visited[newurl] = visited.get(newurl, 0) + 1
    
        # Don't close the fp until we are sure that we won't use it
        # with HTTPError.
        fp.read()
        fp.close()
    
&gt;       return self.parent.open(new, timeout=req.timeout)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:755: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;, fullurl = &lt;urllib.request.Request object at 0x7f94ce8ee340&gt;, data = None
timeout = &lt;object object at 0x7f9519ac1ab0&gt;

    def open(self, fullurl, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT):
        # accept a URL or a Request object
        if isinstance(fullurl, str):
            req = Request(fullurl, data)
        else:
            req = fullurl
            if data is not None:
                req.data = data
    
        req.timeout = timeout
        protocol = req.type
    
        # pre-process request
        meth_name = protocol+"_request"
        for processor in self.process_request.get(protocol, []):
            meth = getattr(processor, meth_name)
            req = meth(req)
    
        sys.audit('urllib.Request', req.full_url, req.data, req.headers, req.get_method())
&gt;       response = self._open(req, data)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:525: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;, req = &lt;urllib.request.Request object at 0x7f94ce8ee340&gt;, data = None

    def _open(self, req, data=None):
        result = self._call_chain(self.handle_open, 'default',
                                  'default_open', req)
        if result:
            return result
    
        protocol = req.type
&gt;       result = self._call_chain(self.handle_open, protocol, protocol +
                                  '_open', req)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:542: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;
chain = {'data': [&lt;urllib.request.DataHandler object at 0x7f94ce8ee160&gt;], 'file': [&lt;urllib.request.FileHandler object at 0x7f9...ib.request.FTPHandler object at 0x7f94ce8ee130&gt;], 'http': [&lt;urllib.request.HTTPHandler object at 0x7f94ce8e08b0&gt;], ...}
kind = 'https', meth_name = 'https_open', args = (&lt;urllib.request.Request object at 0x7f94ce8ee340&gt;,)
handlers = [&lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;], handler = &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;
func = &lt;bound method HTTPSHandler.https_open of &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;&gt;

    def _call_chain(self, chain, kind, meth_name, *args):
        # Handlers raise an exception if no one else should try to handle
        # the request, or return None if they can't but another handler
        # could.  Otherwise, they return the response.
        handlers = chain.get(kind, ())
        for handler in handlers:
            func = getattr(handler, meth_name)
&gt;           result = func(*args)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:502: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;, req = &lt;urllib.request.Request object at 0x7f94ce8ee340&gt;

    def https_open(self, req):
&gt;       return self.do_open(http.client.HTTPSConnection, req,
            context=self._context, check_hostname=self._check_hostname)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:1397: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;, http_class = &lt;class 'http.client.HTTPSConnection'&gt;
req = &lt;urllib.request.Request object at 0x7f94ce8ee340&gt;, http_conn_args = {'check_hostname': None, 'context': None}, host = 'www.logos.t.u-tokyo.ac.jp'
h = &lt;http.client.HTTPSConnection object at 0x7f94ce8ee1c0&gt;

    def do_open(self, http_class, req, **http_conn_args):
        """Return an HTTPResponse object for the request, using http_class.
    
        http_class must implement the HTTPConnection API from http.client.
        """
        host = req.host
        if not host:
            raise URLError('no host given')
    
        # will parse host:port
        h = http_class(host, timeout=req.timeout, **http_conn_args)
        h.set_debuglevel(self._debuglevel)
    
        headers = dict(req.unredirected_hdrs)
        headers.update({k: v for k, v in req.headers.items()
                        if k not in headers})
    
        # TODO(jhylton): Should this be redesigned to handle
        # persistent connections?
    
        # We want to make an HTTP/1.1 request, but the addinfourl
        # class isn't prepared to deal with a persistent connection.
        # It will try to read all remaining data from the socket,
        # which will block while the server waits for the next request.
        # So make sure the connection gets closed after the (only)
        # request.
        headers["Connection"] = "close"
        headers = {name.title(): val for name, val in headers.items()}
    
        if req._tunnel_host:
            tunnel_headers = {}
            proxy_auth_hdr = "Proxy-Authorization"
            if proxy_auth_hdr in headers:
                tunnel_headers[proxy_auth_hdr] = headers[proxy_auth_hdr]
                # Proxy-Authorization should not be sent to origin
                # server.
                del headers[proxy_auth_hdr]
            h.set_tunnel(req._tunnel_host, headers=tunnel_headers)
    
        try:
            try:
                h.request(req.get_method(), req.selector, req.data, headers,
                          encode_chunked=req.has_header('Transfer-encoding'))
            except OSError as err: # timeout error
                raise URLError(err)
&gt;           r = h.getresponse()

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:1358: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;http.client.HTTPSConnection object at 0x7f94ce8ee1c0&gt;

    def getresponse(self):
        """Get the response from the server.
    
        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.
    
        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        """
    
        # if a prior response has been completed, then forget about it.
        if self.__response and self.__response.isclosed():
            self.__response = None
    
        # if a prior response exists, then it must be completed (otherwise, we
        # cannot read this response's header to determine the connection-close
        # behavior)
        #
        # note: if a prior response existed, but was connection-close, then the
        # socket and response were made independent of this HTTPConnection
        # object since a new request requires that we open a whole new
        # connection
        #
        # this means the prior response had one of two states:
        #   1) will_close: this connection was reset and the prior socket and
        #                  response operate independently
        #   2) persistent: the response was retained and we await its
        #                  isclosed() status to become true.
        #
        if self.__state != _CS_REQ_SENT or self.__response:
            raise ResponseNotReady(self.__state)
    
        if self.debuglevel &gt; 0:
            response = self.response_class(self.sock, self.debuglevel,
                                           method=self._method)
        else:
            response = self.response_class(self.sock, method=self._method)
    
        try:
            try:
&gt;               response.begin()

../../../miniconda3/envs/pytorch/lib/python3.8/http/client.py:1348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;http.client.HTTPResponse object at 0x7f94ce8ee4c0&gt;

    def begin(self):
        if self.headers is not None:
            # we've already started reading the response
            return
    
        # read until we get a non-100 response
        while True:
&gt;           version, status, reason = self._read_status()

../../../miniconda3/envs/pytorch/lib/python3.8/http/client.py:316: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;http.client.HTTPResponse object at 0x7f94ce8ee4c0&gt;

    def _read_status(self):
&gt;       line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")

../../../miniconda3/envs/pytorch/lib/python3.8/http/client.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;socket.SocketIO object at 0x7f94ce8ee550&gt;, b = &lt;memory at 0x7f94cea30700&gt;

    def readinto(self, b):
        """Read up to len(b) bytes into the writable buffer *b* and return
        the number of bytes read.  If the socket is non-blocking and no bytes
        are available, None is returned.
    
        If *b* is non-empty, a 0 return value indicates that the connection
        was shutdown at the other end.
        """
        self._checkClosed()
        self._checkReadable()
        if self._timeout_occurred:
            raise OSError("cannot read from timed out object")
        while True:
            try:
&gt;               return self._sock.recv_into(b)

../../../miniconda3/envs/pytorch/lib/python3.8/socket.py:669: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6&gt;, buffer = &lt;memory at 0x7f94cea30700&gt;, nbytes = 8192
flags = 0

    def recv_into(self, buffer, nbytes=None, flags=0):
        self._checkClosed()
        if buffer and (nbytes is None):
            nbytes = len(buffer)
        elif nbytes is None:
            nbytes = 1024
        if self._sslobj is not None:
            if flags != 0:
                raise ValueError(
                  "non-zero flags not allowed in calls to recv_into() on %s" %
                  self.__class__)
&gt;           return self.read(nbytes, buffer)

../../../miniconda3/envs/pytorch/lib/python3.8/ssl.py:1241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6&gt;, len = 8192, buffer = &lt;memory at 0x7f94cea30700&gt;

    def read(self, len=1024, buffer=None):
        """Read up to LEN bytes and return them.
        Return zero-length string on EOF."""
    
        self._checkClosed()
        if self._sslobj is None:
            raise ValueError("Read on closed or unwrapped SSL socket.")
        try:
            if buffer is not None:
&gt;               return self._sslobj.read(len, buffer)
E               KeyboardInterrupt

../../../miniconda3/envs/pytorch/lib/python3.8/ssl.py:1099: KeyboardInterrupt

During handling of the above exception, another exception occurred:

self = &lt;torchtext_unittest.test_build.TestVocab testMethod=test_download_charngram_vectors&gt;

    def test_download_charngram_vectors(self) -&gt; None:
        # Build a vocab and get vectors twice to test caching.
        for _ in range(2):
&gt;           vectors = torchtext.vocab.CharNGram()

torchtext_unittest/test_build.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../torchtext/vocab/vectors.py:239: in __init__
    super(CharNGram, self).__init__(self.name, url=self.url, **kwargs)
../torchtext/vocab/vectors.py:59: in __init__
    self.cache(name, cache, url=url, max_vectors=max_vectors)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;torchtext.vocab.vectors.CharNGram object at 0x7f94cece7580&gt;, name = 'charNgram.txt', cache = '.vector_cache'
url = 'http://www.logos.t.u-tokyo.ac.jp/~hassy/publications/arxiv2016jmt/jmt_pre-trained_embeddings.tar.gz', max_vectors = None

    def cache(self, name, cache, url=None, max_vectors=None):
        import ssl
    
        ssl._create_default_https_context = ssl._create_unverified_context
        if os.path.isfile(name):
            path = name
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = os.path.join(cache, os.path.basename(name)) + file_suffix
        else:
            path = os.path.join(cache, name)
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = path + file_suffix
    
        if not os.path.isfile(path_pt):
            if not os.path.isfile(path) and url:
                logger.info("Downloading vectors from {}".format(url))
                if not os.path.exists(cache):
                    os.makedirs(cache)
                dest = os.path.join(cache, os.path.basename(url))
                if not os.path.isfile(dest):
                    with tqdm(unit="B", unit_scale=True, miniters=1, desc=dest) as t:
                        try:
                            urlretrieve(url, dest, reporthook=reporthook(t))
                        except KeyboardInterrupt as e:  # remove the partial zip file
&gt;                           os.remove(dest)
E                           FileNotFoundError: [Errno 2] No such file or directory: '.vector_cache/jmt_pre-trained_embeddings.tar.gz'

../torchtext/vocab/vectors.py:97: FileNotFoundError</failure></testcase><testcase classname="test.torchtext_unittest.test_build.TestVocab" name="test_download_custom_vectors" time="0.218"><failure message="FileNotFoundError: [Errno 2] No such file or directory: '.vector_cache/wiki.simple.vec'">self = &lt;torchtext.vocab.vectors.Vectors object at 0x7f94cdfd2730&gt;, name = 'wiki.simple.vec', cache = '.vector_cache'
url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec', max_vectors = None

    def cache(self, name, cache, url=None, max_vectors=None):
        import ssl
    
        ssl._create_default_https_context = ssl._create_unverified_context
        if os.path.isfile(name):
            path = name
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = os.path.join(cache, os.path.basename(name)) + file_suffix
        else:
            path = os.path.join(cache, name)
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = path + file_suffix
    
        if not os.path.isfile(path_pt):
            if not os.path.isfile(path) and url:
                logger.info("Downloading vectors from {}".format(url))
                if not os.path.exists(cache):
                    os.makedirs(cache)
                dest = os.path.join(cache, os.path.basename(url))
                if not os.path.isfile(dest):
                    with tqdm(unit="B", unit_scale=True, miniters=1, desc=dest) as t:
                        try:
&gt;                           urlretrieve(url, dest, reporthook=reporthook(t))

../torchtext/vocab/vectors.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec', filename = '.vector_cache/wiki.simple.vec'
reporthook = &lt;function reporthook.&lt;locals&gt;.inner at 0x7f94ce069ee0&gt;, data = None

    def urlretrieve(url, filename=None, reporthook=None, data=None):
        """
        Retrieve a URL into a temporary location on disk.
    
        Requires a URL argument. If a filename is passed, it is used as
        the temporary file location. The reporthook argument should be
        a callable that accepts a block number, a read size, and the
        total file size of the URL target. The data argument should be
        valid URL encoded data.
    
        If a filename is passed and the URL points to a local resource,
        the result is a copy from local file to new file.
    
        Returns a tuple containing the path to the newly created
        data file as well as the resulting HTTPMessage object.
        """
        url_type, path = _splittype(url)
    
&gt;       with contextlib.closing(urlopen(url, data)) as fp:

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec', data = None, timeout = &lt;object object at 0x7f9519ac1ab0&gt;

    def urlopen(url, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
                *, cafile=None, capath=None, cadefault=False, context=None):
        '''Open the URL url, which can be either a string or a Request object.
    
        *data* must be an object specifying additional data to be sent to
        the server, or None if no such data is needed.  See Request for
        details.
    
        urllib.request module uses HTTP/1.1 and includes a "Connection:close"
        header in its HTTP requests.
    
        The optional *timeout* parameter specifies a timeout in seconds for
        blocking operations like the connection attempt (if not specified, the
        global default timeout setting will be used). This only works for HTTP,
        HTTPS and FTP connections.
    
        If *context* is specified, it must be a ssl.SSLContext instance describing
        the various SSL options. See HTTPSConnection for more details.
    
        The optional *cafile* and *capath* parameters specify a set of trusted CA
        certificates for HTTPS requests. cafile should point to a single file
        containing a bundle of CA certificates, whereas capath should point to a
        directory of hashed certificate files. More information can be found in
        ssl.SSLContext.load_verify_locations().
    
        The *cadefault* parameter is ignored.
    
        This function always returns an object which can work as a context
        manager and has methods such as
    
        * geturl() - return the URL of the resource retrieved, commonly used to
          determine if a redirect was followed
    
        * info() - return the meta-information of the page, such as headers, in the
          form of an email.message_from_string() instance (see Quick Reference to
          HTTP Headers)
    
        * getcode() - return the HTTP status code of the response.  Raises URLError
          on errors.
    
        For HTTP and HTTPS URLs, this function returns a http.client.HTTPResponse
        object slightly modified. In addition to the three new methods above, the
        msg attribute contains the same information as the reason attribute ---
        the reason phrase returned by the server --- instead of the response
        headers as it is specified in the documentation for HTTPResponse.
    
        For FTP, file, and data URLs and requests explicitly handled by legacy
        URLopener and FancyURLopener classes, this function returns a
        urllib.response.addinfourl object.
    
        Note that None may be returned if no handler handles the request (though
        the default installed global OpenerDirector uses UnknownHandler to ensure
        this never happens).
    
        In addition, if proxy settings are detected (for example, when a *_proxy
        environment variable like http_proxy is set), ProxyHandler is default
        installed and makes sure the requests are handled through the proxy.
    
        '''
        global _opener
        if cafile or capath or cadefault:
            import warnings
            warnings.warn("cafile, capath and cadefault are deprecated, use a "
                          "custom context instead.", DeprecationWarning, 2)
            if context is not None:
                raise ValueError(
                    "You can't pass both context and any of cafile, capath, and "
                    "cadefault"
                )
            if not _have_ssl:
                raise ValueError('SSL support not available')
            context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH,
                                                 cafile=cafile,
                                                 capath=capath)
            https_handler = HTTPSHandler(context=context)
            opener = build_opener(https_handler)
        elif context:
            https_handler = HTTPSHandler(context=context)
            opener = build_opener(https_handler)
        elif _opener is None:
            _opener = opener = build_opener()
        else:
            opener = _opener
&gt;       return opener.open(url, data, timeout)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;, fullurl = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec', data = None
timeout = &lt;object object at 0x7f9519ac1ab0&gt;

    def open(self, fullurl, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT):
        # accept a URL or a Request object
        if isinstance(fullurl, str):
            req = Request(fullurl, data)
        else:
            req = fullurl
            if data is not None:
                req.data = data
    
        req.timeout = timeout
        protocol = req.type
    
        # pre-process request
        meth_name = protocol+"_request"
        for processor in self.process_request.get(protocol, []):
            meth = getattr(processor, meth_name)
            req = meth(req)
    
        sys.audit('urllib.Request', req.full_url, req.data, req.headers, req.get_method())
&gt;       response = self._open(req, data)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:525: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;, req = &lt;urllib.request.Request object at 0x7f94cdfd2af0&gt;, data = None

    def _open(self, req, data=None):
        result = self._call_chain(self.handle_open, 'default',
                                  'default_open', req)
        if result:
            return result
    
        protocol = req.type
&gt;       result = self._call_chain(self.handle_open, protocol, protocol +
                                  '_open', req)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:542: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.OpenerDirector object at 0x7f94ce8e0910&gt;
chain = {'data': [&lt;urllib.request.DataHandler object at 0x7f94ce8ee160&gt;], 'file': [&lt;urllib.request.FileHandler object at 0x7f9...ib.request.FTPHandler object at 0x7f94ce8ee130&gt;], 'http': [&lt;urllib.request.HTTPHandler object at 0x7f94ce8e08b0&gt;], ...}
kind = 'https', meth_name = 'https_open', args = (&lt;urllib.request.Request object at 0x7f94cdfd2af0&gt;,)
handlers = [&lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;], handler = &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;
func = &lt;bound method HTTPSHandler.https_open of &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;&gt;

    def _call_chain(self, chain, kind, meth_name, *args):
        # Handlers raise an exception if no one else should try to handle
        # the request, or return None if they can't but another handler
        # could.  Otherwise, they return the response.
        handlers = chain.get(kind, ())
        for handler in handlers:
            func = getattr(handler, meth_name)
&gt;           result = func(*args)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:502: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;, req = &lt;urllib.request.Request object at 0x7f94cdfd2af0&gt;

    def https_open(self, req):
&gt;       return self.do_open(http.client.HTTPSConnection, req,
            context=self._context, check_hostname=self._check_hostname)

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:1397: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;urllib.request.HTTPSHandler object at 0x7f94ce8ee2b0&gt;, http_class = &lt;class 'http.client.HTTPSConnection'&gt;
req = &lt;urllib.request.Request object at 0x7f94cdfd2af0&gt;, http_conn_args = {'check_hostname': None, 'context': None}, host = 'dl.fbaipublicfiles.com'
h = &lt;http.client.HTTPSConnection object at 0x7f94cdfd2bb0&gt;

    def do_open(self, http_class, req, **http_conn_args):
        """Return an HTTPResponse object for the request, using http_class.
    
        http_class must implement the HTTPConnection API from http.client.
        """
        host = req.host
        if not host:
            raise URLError('no host given')
    
        # will parse host:port
        h = http_class(host, timeout=req.timeout, **http_conn_args)
        h.set_debuglevel(self._debuglevel)
    
        headers = dict(req.unredirected_hdrs)
        headers.update({k: v for k, v in req.headers.items()
                        if k not in headers})
    
        # TODO(jhylton): Should this be redesigned to handle
        # persistent connections?
    
        # We want to make an HTTP/1.1 request, but the addinfourl
        # class isn't prepared to deal with a persistent connection.
        # It will try to read all remaining data from the socket,
        # which will block while the server waits for the next request.
        # So make sure the connection gets closed after the (only)
        # request.
        headers["Connection"] = "close"
        headers = {name.title(): val for name, val in headers.items()}
    
        if req._tunnel_host:
            tunnel_headers = {}
            proxy_auth_hdr = "Proxy-Authorization"
            if proxy_auth_hdr in headers:
                tunnel_headers[proxy_auth_hdr] = headers[proxy_auth_hdr]
                # Proxy-Authorization should not be sent to origin
                # server.
                del headers[proxy_auth_hdr]
            h.set_tunnel(req._tunnel_host, headers=tunnel_headers)
    
        try:
            try:
                h.request(req.get_method(), req.selector, req.data, headers,
                          encode_chunked=req.has_header('Transfer-encoding'))
            except OSError as err: # timeout error
                raise URLError(err)
&gt;           r = h.getresponse()

../../../miniconda3/envs/pytorch/lib/python3.8/urllib/request.py:1358: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;http.client.HTTPSConnection object at 0x7f94cdfd2bb0&gt;

    def getresponse(self):
        """Get the response from the server.
    
        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.
    
        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        """
    
        # if a prior response has been completed, then forget about it.
        if self.__response and self.__response.isclosed():
            self.__response = None
    
        # if a prior response exists, then it must be completed (otherwise, we
        # cannot read this response's header to determine the connection-close
        # behavior)
        #
        # note: if a prior response existed, but was connection-close, then the
        # socket and response were made independent of this HTTPConnection
        # object since a new request requires that we open a whole new
        # connection
        #
        # this means the prior response had one of two states:
        #   1) will_close: this connection was reset and the prior socket and
        #                  response operate independently
        #   2) persistent: the response was retained and we await its
        #                  isclosed() status to become true.
        #
        if self.__state != _CS_REQ_SENT or self.__response:
            raise ResponseNotReady(self.__state)
    
        if self.debuglevel &gt; 0:
            response = self.response_class(self.sock, self.debuglevel,
                                           method=self._method)
        else:
            response = self.response_class(self.sock, method=self._method)
    
        try:
            try:
&gt;               response.begin()

../../../miniconda3/envs/pytorch/lib/python3.8/http/client.py:1348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;http.client.HTTPResponse object at 0x7f94cdfd2be0&gt;

    def begin(self):
        if self.headers is not None:
            # we've already started reading the response
            return
    
        # read until we get a non-100 response
        while True:
&gt;           version, status, reason = self._read_status()

../../../miniconda3/envs/pytorch/lib/python3.8/http/client.py:316: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;http.client.HTTPResponse object at 0x7f94cdfd2be0&gt;

    def _read_status(self):
&gt;       line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")

../../../miniconda3/envs/pytorch/lib/python3.8/http/client.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;socket.SocketIO object at 0x7f94cdfd2ac0&gt;, b = &lt;memory at 0x7f94ce004880&gt;

    def readinto(self, b):
        """Read up to len(b) bytes into the writable buffer *b* and return
        the number of bytes read.  If the socket is non-blocking and no bytes
        are available, None is returned.
    
        If *b* is non-empty, a 0 return value indicates that the connection
        was shutdown at the other end.
        """
        self._checkClosed()
        self._checkReadable()
        if self._timeout_occurred:
            raise OSError("cannot read from timed out object")
        while True:
            try:
&gt;               return self._sock.recv_into(b)

../../../miniconda3/envs/pytorch/lib/python3.8/socket.py:669: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6&gt;, buffer = &lt;memory at 0x7f94ce004880&gt;, nbytes = 8192
flags = 0

    def recv_into(self, buffer, nbytes=None, flags=0):
        self._checkClosed()
        if buffer and (nbytes is None):
            nbytes = len(buffer)
        elif nbytes is None:
            nbytes = 1024
        if self._sslobj is not None:
            if flags != 0:
                raise ValueError(
                  "non-zero flags not allowed in calls to recv_into() on %s" %
                  self.__class__)
&gt;           return self.read(nbytes, buffer)

../../../miniconda3/envs/pytorch/lib/python3.8/ssl.py:1241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6&gt;, len = 8192, buffer = &lt;memory at 0x7f94ce004880&gt;

    def read(self, len=1024, buffer=None):
        """Read up to LEN bytes and return them.
        Return zero-length string on EOF."""
    
        self._checkClosed()
        if self._sslobj is None:
            raise ValueError("Read on closed or unwrapped SSL socket.")
        try:
            if buffer is not None:
&gt;               return self._sslobj.read(len, buffer)
E               KeyboardInterrupt

../../../miniconda3/envs/pytorch/lib/python3.8/ssl.py:1099: KeyboardInterrupt

During handling of the above exception, another exception occurred:

self = &lt;torchtext_unittest.test_build.TestVocab testMethod=test_download_custom_vectors&gt;

    def test_download_custom_vectors(self) -&gt; None:
        # Build a vocab and get vectors twice to test caching.
        for _ in range(2):
&gt;           vectors = torchtext.vocab.Vectors("wiki.simple.vec", url=torchtext.vocab.FastText.url_base.format("simple"))

torchtext_unittest/test_build.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../torchtext/vocab/vectors.py:59: in __init__
    self.cache(name, cache, url=url, max_vectors=max_vectors)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;torchtext.vocab.vectors.Vectors object at 0x7f94cdfd2730&gt;, name = 'wiki.simple.vec', cache = '.vector_cache'
url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec', max_vectors = None

    def cache(self, name, cache, url=None, max_vectors=None):
        import ssl
    
        ssl._create_default_https_context = ssl._create_unverified_context
        if os.path.isfile(name):
            path = name
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = os.path.join(cache, os.path.basename(name)) + file_suffix
        else:
            path = os.path.join(cache, name)
            if max_vectors:
                file_suffix = "_{}.pt".format(max_vectors)
            else:
                file_suffix = ".pt"
            path_pt = path + file_suffix
    
        if not os.path.isfile(path_pt):
            if not os.path.isfile(path) and url:
                logger.info("Downloading vectors from {}".format(url))
                if not os.path.exists(cache):
                    os.makedirs(cache)
                dest = os.path.join(cache, os.path.basename(url))
                if not os.path.isfile(dest):
                    with tqdm(unit="B", unit_scale=True, miniters=1, desc=dest) as t:
                        try:
                            urlretrieve(url, dest, reporthook=reporthook(t))
                        except KeyboardInterrupt as e:  # remove the partial zip file
&gt;                           os.remove(dest)
E                           FileNotFoundError: [Errno 2] No such file or directory: '.vector_cache/wiki.simple.vec'

../torchtext/vocab/vectors.py:97: FileNotFoundError</failure></testcase><testcase time="0.000" /></testsuite></testsuites>